{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match regional geodetic mass balance\n",
    "The OGGM function `match_regional_geodetic_mb()` shifts the mass balance residuals $\\beta^*$ to match the observations presented by [Davaze et al. 2020](https://www.frontiersin.org/articles/10.3389/feart.2020.00149/full). Hereafter I'll have a look at it and re-implement it to work with the VAS model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OGGM flowline model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import internal and externals libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger('equilibrium-runs')\n",
    "\n",
    "# import the needed OGGM modules\n",
    "from oggm import cfg, utils, workflow\n",
    "from oggm.core import gis, climate, flowline\n",
    "\n",
    "\n",
    "log.info('Starting run')\n",
    "\n",
    "# specify glaciers by RGI IDs (INPUT)\n",
    "rgi_ids = ['RGI60-11.00897']\n",
    "\n",
    "# compute RGI region and version from RGI IDs\n",
    "# assuming all RGI IDs are from within one version and region\n",
    "rgi_region = (rgi_ids[0].split('-')[-1]).split('.')[0]\n",
    "rgi_version = (rgi_ids[0].split('-')[0])[-2:-1]\n",
    "\n",
    "# load default parameter file\n",
    "cfg.initialize()\n",
    "\n",
    "# specify path to working and output directories (INPUT)\n",
    "WORKING_DIR = '/Users/oberrauch/work/master/working_directories/oggm_run/'\n",
    "OUTPUT_DIR = '/Users/oberrauch/work/master/data/oggm_run/'\n",
    "\n",
    "# create working directory\n",
    "utils.mkdir(WORKING_DIR)\n",
    "utils.mkdir(OUTPUT_DIR)\n",
    "# set path to working directory\n",
    "cfg.PATHS['working_dir'] = WORKING_DIR\n",
    "# set RGI version and region\n",
    "cfg.PARAMS['rgi_version'] = rgi_version\n",
    "# define how many grid points to use around the glacier,\n",
    "# if you expect the glacier to grow large use a larger border\n",
    "cfg.PARAMS['border'] = 10\n",
    "# use default climate (=CRU)\n",
    "# for HISTALP uncomment the following lines (INPUT)\n",
    "# cfg.PARAMS['baseline_climate'] = 'HISTALP'\n",
    "# cfg.PARAMS['prcp_scaling_factor'] = 1.75\n",
    "# cfg.PARAMS['temp_melt'] = -1.75\n",
    "# cfg.PARAMS['run_mb_calibration'] = False\n",
    "\n",
    "# the bias is defined to be zero during the calibration process,\n",
    "# which is why we don't use it here to reproduce the results\n",
    "cfg.PARAMS['use_bias_for_run'] = True\n",
    "# set minimum ice thickness to include in glacier length computation\n",
    "# this reduces weird spikes in length records\n",
    "cfg.PARAMS['min_ice_thick_for_length'] = 0.1\n",
    "\n",
    "# read RGI entry for the glaciers as DataFrame\n",
    "# containing the outline area as shapefile\n",
    "rgidf = utils.get_rgi_glacier_entities(rgi_ids)\n",
    "\n",
    "# get and set path to intersect shapefile\n",
    "intersects_db = utils.get_rgi_intersects_region_file(region=rgi_region)\n",
    "cfg.set_intersects_db(intersects_db)\n",
    "\n",
    "# sort by area for more efficient parallel computing\n",
    "rgidf = rgidf.sort_values('Area', ascending=False)\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "# operational run, all glaciers should run\n",
    "cfg.PARAMS['continue_on_error'] = True\n",
    "\n",
    "# initialize the GlacierDirectory\n",
    "gdirs = workflow.init_glacier_directories(rgidf, reset=False, force=True)\n",
    "\n",
    "# run gis tasks\n",
    "workflow.gis_prepro_tasks(gdirs)\n",
    "# run climate tasks\n",
    "workflow.execute_entity_task(climate.process_climate_data, gdirs)\n",
    "# compute local t* and the corresponding mu*\n",
    "workflow.execute_entity_task(climate.local_t_star, gdirs)\n",
    "\n",
    "\n",
    "workflow.execute_entity_task(climate.mu_star_calibration, gdirs)\n",
    "# run inversion tasks\n",
    "workflow.inversion_tasks(gdirs)\n",
    "# finalize preprocessing\n",
    "workflow.execute_entity_task(flowline.init_present_time_glacier, gdirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `match_regional_geodetic_mb()` just to see if it works and what its output is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm import workflow\n",
    "workflow.match_regional_geodetic_mb(gdirs, rgi_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAS model setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 16:43:57: oggm.cfg: Reading default parameters from the OGGM `params.cfg` configuration file.\n",
      "2021-01-21 16:43:57: oggm.cfg: Multiprocessing switched ON according to the parameter file.\n",
      "2021-01-21 16:43:57: oggm.cfg: Multiprocessing: using all available processors (N=4)\n",
      "2021-01-21 16:43:57: oggm.utils: Checking the download verification file checksum...\n",
      "2021-01-21 16:43:58: oggm.cfg: WARNING: adding an unknown parameter `vas_c_area_m2`:`0.191` to PARAMS.\n",
      "2021-01-21 16:43:58: oggm.cfg: WARNING: adding an unknown parameter `vas_gamma_area`:`1.375` to PARAMS.\n",
      "2021-01-21 16:43:58: oggm.cfg: WARNING: adding an unknown parameter `vas_c_length_m`:`4.5507` to PARAMS.\n",
      "2021-01-21 16:43:58: oggm.cfg: WARNING: adding an unknown parameter `vas_q_length`:`2.2` to PARAMS.\n",
      "2021-01-21 16:43:58: oggm.cfg: PARAMS['rgi_version'] changed from `61` to `6`.\n",
      "2021-01-21 16:43:58: oggm.cfg: PARAMS['baseline_climate'] changed from `CRU` to `HISTALP`.\n",
      "2021-01-21 16:43:58: oggm.cfg: PARAMS['temp_melt'] changed from `-1.0` to `-0.5`.\n",
      "2021-01-21 16:43:58: oggm.cfg: PARAMS['min_ice_thick_for_length'] changed from `0.0` to `0.1`.\n",
      "2021-01-21 16:43:59: oggm.workflow: Execute entity task GlacierDirectory on 1 glaciers\n",
      "2021-01-21 16:44:00: oggm.workflow: Execute entity task define_glacier_region on 1 glaciers\n",
      "2021-01-21 16:44:01: oggm.core.gis: (RGI60-11.00897) define_glacier_region\n",
      "2021-01-21 16:44:01: oggm.workflow: Execute entity task glacier_masks on 1 glaciers\n",
      "2021-01-21 16:44:01: oggm.core.gis: (RGI60-11.00897) glacier_masks\n",
      "2021-01-21 16:44:02: oggm.workflow: Execute entity task process_climate_data on 1 glaciers\n",
      "2021-01-21 16:44:02: oggm.core.climate: (RGI60-11.00897) process_climate_data\n",
      "2021-01-21 16:44:02: oggm.shop.histalp: (RGI60-11.00897) process_histalp_data\n",
      "2021-01-21 16:44:02: oggm.utils: /Users/oberrauch/OGGM/download_cache/www.zamg.ac.at/histalp/download/grid5m/HISTALP_temperature_1780-2014.nc.bz2 verified successfully.\n",
      "2021-01-21 16:44:02: oggm.utils: /Users/oberrauch/OGGM/download_cache/www.zamg.ac.at/histalp/download/grid5m/HISTALP_precipitation_all_abs_1801-2014.nc.bz2 verified successfully.\n",
      "2021-01-21 16:44:05: oggm.workflow: Execute entity task local_t_star on 1 glaciers\n",
      "2021-01-21 16:44:05: oggm_vas.core: (RGI60-11.00897) local_t_star\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 16:44:19: oggm_vas.core: (RGI60-11.00897) fixed_geometry_mass_balance\n",
      "2021-01-21 16:45:06: oggm.utils: (RGI60-11.00897) glacier_statistics\n"
     ]
    }
   ],
   "source": [
    "# import internal and externals libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "import logging\n",
    "\n",
    "log = logging.getLogger('vas-template')\n",
    "\n",
    "# import the needed OGGM modules\n",
    "from oggm import cfg, utils, workflow\n",
    "from oggm.core import gis, climate, flowline\n",
    "import oggm_vas as vascaling\n",
    "\n",
    "log.info('Starting run')\n",
    "\n",
    "# specify glaciers by RGI IDs (INPUT)\n",
    "rgi_ids = ['RGI60-11.00897']\n",
    "\n",
    "# compute RGI region and version from RGI IDs\n",
    "# assuming all they are all the same\n",
    "rgi_region = (rgi_ids[0].split('-')[-1]).split('.')[0]\n",
    "rgi_version = (rgi_ids[0].split('-')[0])[-2:-1]\n",
    "\n",
    "# load default parameter file\n",
    "vascaling.initialize()\n",
    "\n",
    "# get environmental variables for working and output directories\n",
    "WORKING_DIR = '/Users/oberrauch/work/master/working_directories/vas_run/'\n",
    "OUTPUT_DIR = '/Users/oberrauch/work/master/data/vas_run/'\n",
    "\n",
    "# create working directory\n",
    "utils.mkdir(WORKING_DIR)\n",
    "utils.mkdir(OUTPUT_DIR)\n",
    "# set path to working directory\n",
    "cfg.PATHS['working_dir'] = WORKING_DIR\n",
    "# set RGI version and region\n",
    "cfg.PARAMS['rgi_version'] = rgi_version\n",
    "# define how many grid points to use around the glacier,\n",
    "# if you expect the glacier to grow large use a larger border\n",
    "cfg.PARAMS['border'] = 20\n",
    "# we use HistAlp climate data\n",
    "cfg.PARAMS['baseline_climate'] = 'HISTALP'\n",
    "# set the mb hyper parameters accordingly\n",
    "cfg.PARAMS['prcp_scaling_factor'] = 2.5\n",
    "cfg.PARAMS['temp_melt'] = -0.5\n",
    "cfg.PARAMS['run_mb_calibration'] = False\n",
    "# set minimum ice thickness to include in glacier length computation\n",
    "# this reduces weird spikes in length records\n",
    "cfg.PARAMS['min_ice_thick_for_length'] = 0.1\n",
    "\n",
    "# the bias is defined to be zero during the calibration process,\n",
    "# which is why we don't use it here to reproduce the results\n",
    "cfg.PARAMS['use_bias_for_run'] = True\n",
    "\n",
    "# read RGI entry for the glaciers as DataFrame\n",
    "# containing the outline area as shapefile\n",
    "rgidf = utils.get_rgi_glacier_entities(rgi_ids)\n",
    "\n",
    "# get and set path to intersect shapefile\n",
    "intersects_db = utils.get_rgi_intersects_region_file(region=rgi_region)\n",
    "cfg.set_intersects_db(intersects_db)\n",
    "\n",
    "# sort by area for more efficient parallel computing\n",
    "rgidf = rgidf.sort_values('Area', ascending=False)\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "# operational run, all glaciers should run\n",
    "cfg.PARAMS['continue_on_error'] = False\n",
    "\n",
    "# initialize the GlacierDirectory\n",
    "gdirs = workflow.init_glacier_directories(rgidf, reset=False, force=True)\n",
    "\n",
    "# define the local grid and glacier mask\n",
    "workflow.execute_entity_task(gis.define_glacier_region, gdirs,\n",
    "                             source=None)\n",
    "workflow.execute_entity_task(gis.glacier_masks, gdirs)\n",
    "# process the given climate file\n",
    "workflow.execute_entity_task(climate.process_climate_data, gdirs)\n",
    "# compute local t* and the corresponding mu*\n",
    "workflow.execute_entity_task(vascaling.local_t_star, gdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 16:44:19: oggm.workflow: Execute entity task fixed_geometry_mass_balance on 1 glaciers\n"
     ]
    }
   ],
   "source": [
    "# Get the mass-balance VAS would give out of the box\n",
    "df = vascaling.compile_fixed_geometry_mass_balance(gdirs, path=False)\n",
    "df = df.dropna(axis=0, how='all').dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 16:45:06: oggm.workflow: Execute entity task glacier_statistics on 1 glaciers\n"
     ]
    }
   ],
   "source": [
    "# And also the Area and calving fluxes\n",
    "dfs = utils.compile_glacier_statistics(gdirs, path=False)\n",
    "odf = pd.DataFrame(df.loc[2006:2018].mean(), columns=['SMB'])\n",
    "odf['AREA'] = dfs.rgi_area_km2 * 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgi_reg = '11'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdf = 'rgi62_areas.csv'\n",
    "rdf = pd.read_csv(utils.get_demo_file(rdf), dtype={'O1Region': str})\n",
    "ref_area = rdf.loc[rdf['O1Region'] == rgi_reg].iloc[0]['AreaNoC2NoNominal']\n",
    "diff = (1 - odf['AREA'].sum() * 1e-6 / ref_area) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O1Region</th>\n",
       "      <th>Area</th>\n",
       "      <th>IsNominal</th>\n",
       "      <th>IsLandTerminating</th>\n",
       "      <th>IsTidewater</th>\n",
       "      <th>IsLakeTerminating</th>\n",
       "      <th>IsShelfTerminating</th>\n",
       "      <th>IsMarineTerminating</th>\n",
       "      <th>AreaNoC2</th>\n",
       "      <th>AreaNoC2NoNominal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>2092.146</td>\n",
       "      <td>2</td>\n",
       "      <td>3927</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2092.146</td>\n",
       "      <td>2091.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   O1Region      Area  IsNominal  IsLandTerminating  IsTidewater  \\\n",
       "10       11  2092.146          2               3927            0   \n",
       "\n",
       "    IsLakeTerminating  IsShelfTerminating  IsMarineTerminating  AreaNoC2  \\\n",
       "10                  0                   0                    0  2092.146   \n",
       "\n",
       "    AreaNoC2NoNominal  \n",
       "10            2091.98  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-01-21 16:02:06: oggm.workflow: Execute entity task fixed_geometry_mass_balance on 1 glaciers\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/oberrauch/work/master/working_directories/vas_run/per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00897/inversion_flowlines.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/Users/oberrauch/miniconda3/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/Users/oberrauch/miniconda3/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"/Users/oberrauch/oggm-fork/oggm/workflow.py\", line 99, in __call__\n    return call_func(gdir, **self.out_kwargs)\n  File \"/Users/oberrauch/oggm-fork/oggm/utils/_workflow.py\", line 488, in _entity_task\n    out = task_func(gdir, **kwargs)\n  File \"/Users/oberrauch/oggm-fork/oggm/core/massbalance.py\", line 1175, in fixed_geometry_mass_balance\n    input_filesuffix=climate_input_filesuffix)\n  File \"/Users/oberrauch/oggm-fork/oggm/core/massbalance.py\", line 958, in __init__\n    fls = gdir.read_pickle('inversion_flowlines')\n  File \"/Users/oberrauch/oggm-fork/oggm/utils/_workflow.py\", line 2249, in read_pickle\n    with _open(fp, 'rb') as f:\n  File \"/Users/oberrauch/miniconda3/envs/oggm_env/lib/python3.6/gzip.py\", line 53, in open\n    binary_file = GzipFile(filename, gz_mode, compresslevel)\n  File \"/Users/oberrauch/miniconda3/envs/oggm_env/lib/python3.6/gzip.py\", line 163, in __init__\n    fileobj = self.myfileobj = builtins.open(filename, mode or 'rb')\nFileNotFoundError: [Errno 2] No such file or directory: '/Users/oberrauch/work/master/working_directories/vas_run/per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00897/inversion_flowlines.pkl'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-70ef675b0f2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Get the mass-balance OGGM would give out of the box\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_fixed_geometry_mass_balance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oggm-fork/oggm/utils/_workflow.py\u001b[0m in \u001b[0;36mcompile_fixed_geometry_mass_balance\u001b[0;34m(gdirs, filesuffix, path, use_inversion_flowlines, ys, ye, years)\u001b[0m\n\u001b[1;32m   1298\u001b[0m     out_df = execute_entity_task(fixed_geometry_mass_balance, gdirs,\n\u001b[1;32m   1299\u001b[0m                                  \u001b[0muse_inversion_flowlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_inversion_flowlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m                                  ys=ys, ye=ye, years=years)\n\u001b[0m\u001b[1;32m   1301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oggm-fork/oggm/workflow.py\u001b[0m in \u001b[0;36mexecute_entity_task\u001b[0;34m(task, gdirs, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'use_multiprocessing'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0mmppool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_mp_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCONFIG_MODIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmppool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgdirs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         '''\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    668\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/oggm_env/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmapstar\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oggm-fork/oggm/workflow.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mgdir_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcall_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oggm-fork/oggm/utils/_workflow.py\u001b[0m in \u001b[0;36m_entity_task\u001b[0;34m()\u001b[0m\n\u001b[1;32m    486\u001b[0m                     \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malarm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task_timeout'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                 \u001b[0mex_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m                 \u001b[0mex_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mex_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'task_timeout'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oggm-fork/oggm/core/massbalance.py\u001b[0m in \u001b[0;36mfixed_geometry_mass_balance\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1173\u001b[0m                                      \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclimate_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m                                      \u001b[0muse_inversion_flowlines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_inversion_flowlines\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m                                      input_filesuffix=climate_input_filesuffix)\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0myears\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oggm-fork/oggm/core/massbalance.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    956\u001b[0m         \u001b[0;31m# Read in the flowlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_inversion_flowlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m             \u001b[0mfls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgdir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inversion_flowlines'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/oggm-fork/oggm/utils/_workflow.py\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m()\u001b[0m\n\u001b[1;32m   2247\u001b[0m         \u001b[0m_open\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_comp\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2248\u001b[0m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilesuffix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilesuffix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2249\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2250\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/oggm_env/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"write\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/oggm_env/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/oberrauch/work/master/working_directories/vas_run/per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00897/inversion_flowlines.pkl'"
     ]
    }
   ],
   "source": [
    "# Get the mass-balance OGGM would give out of the box\n",
    "df = utils.compile_fixed_geometry_mass_balance(gdirs, path=False)\n",
    "df = df.dropna(axis=0, how='all').dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_geometry_mass_balance(gdir, ys=None, ye=None, years=None,\n",
    "                                monthly_step=False,\n",
    "                                use_inversion_flowlines=True,\n",
    "                                climate_filename='climate_historical',\n",
    "                                climate_input_filesuffix=''):\n",
    "    \"\"\"Computes the mass-balance with climate input from e.g. CRU or a GCM.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdir : :py:class:`oggm.GlacierDirectory`\n",
    "        the glacier directory to process\n",
    "    ys : int\n",
    "        start year of the model run (default: from the climate file)\n",
    "        date)\n",
    "    ye : int\n",
    "        end year of the model run (default: from the climate file)\n",
    "    years : array of ints\n",
    "        override ys and ye with the years of your choice\n",
    "    monthly_step : bool\n",
    "        whether to store the diagnostic data at a monthly time step or not\n",
    "        (default is yearly)\n",
    "    use_inversion_flowlines : bool\n",
    "        whether to use the inversion flowlines or the model flowlines\n",
    "    climate_filename : str\n",
    "        name of the climate file, e.g. 'climate_historical' (default) or\n",
    "        'gcm_data'\n",
    "    climate_input_filesuffix: str\n",
    "        filesuffix for the input climate file\n",
    "    \"\"\"\n",
    "\n",
    "    if monthly_step:\n",
    "        raise NotImplementedError('monthly_step not implemented yet')\n",
    "\n",
    "    mb = MultipleFlowlineMassBalance(gdir, mb_model_class=PastMassBalance,\n",
    "                                     filename=climate_filename,\n",
    "                                     use_inversion_flowlines=use_inversion_flowlines,\n",
    "                                     input_filesuffix=climate_input_filesuffix)\n",
    "\n",
    "    if years is None:\n",
    "        if ys is None:\n",
    "            ys = mb.flowline_mb_models[0].ys\n",
    "        if ye is None:\n",
    "            ye = mb.flowline_mb_models[0].ye\n",
    "        years = np.arange(ys, ye + 1)\n",
    "\n",
    "    odf = pd.Series(data=mb.get_specific_mb(year=years),\n",
    "                    index=years)\n",
    "    return odf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_regional_geodetic_mb(gdirs, rgi_reg):\n",
    "    \"\"\"Regional shift of the mass-balance residual to match observations.\n",
    "\n",
    "    This is useful for operational runs, but also quite hacky.\n",
    "    Let's hope we won't need this for too long.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    gdirs : the list of gdirs (ideally the entire region_\n",
    "    rgi_reg : str\n",
    "       the rgi region to match\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the mass-balance OGGM would give out of the box\n",
    "    df = utils.compile_fixed_geometry_mass_balance(gdirs, path=False)\n",
    "    df = df.dropna(axis=0, how='all').dropna(axis=1, how='all')\n",
    "\n",
    "    # And also the Area and calving fluxes\n",
    "    dfs = utils.compile_glacier_statistics(gdirs, path=False)\n",
    "    odf = pd.DataFrame(df.loc[2006:2018].mean(), columns=['SMB'])\n",
    "    odf['AREA'] = dfs.rgi_area_km2 * 1e6\n",
    "    # Just take the calving rate and change its units\n",
    "    # Original units: km3 a-1, to change to mm a-1 (units of specific MB)\n",
    "    rho = cfg.PARAMS['ice_density']\n",
    "    if 'calving_flux' in dfs:\n",
    "        odf['CALVING'] = dfs['calving_flux'].fillna(0) * 1e9 * rho / odf['AREA']\n",
    "    else:\n",
    "        odf['CALVING'] = 0\n",
    "\n",
    "    # We have to drop nans here, which occur when calving glaciers fail to run\n",
    "    odf = odf.dropna()\n",
    "\n",
    "    # Compare area with total RGI area\n",
    "    rdf = 'rgi62_areas.csv'\n",
    "    rdf = pd.read_csv(utils.get_demo_file(rdf), dtype={'O1Region': str})\n",
    "    ref_area = rdf.loc[rdf['O1Region'] == rgi_reg].iloc[0]['AreaNoC2NoNominal']\n",
    "    diff = (1 - odf['AREA'].sum() * 1e-6 / ref_area) * 100\n",
    "    msg = 'Applying geodetic MB correction on RGI reg {}. Diff area: {:.2f}%'\n",
    "    log.workflow(msg.format(rgi_reg, diff))\n",
    "\n",
    "    # Total MB OGGM\n",
    "    out_smb = np.average(odf['SMB'], weights=odf['AREA'])  # for logging\n",
    "    out_cal = np.average(odf['CALVING'], weights=odf['AREA'])  # for logging\n",
    "    smb_oggm = np.average(odf['SMB'] - odf['CALVING'], weights=odf['AREA'])\n",
    "\n",
    "    # Total MB Reference\n",
    "    df = 'table_hugonnet_regions_10yr_20yr_ar6period.csv'\n",
    "    df = pd.read_csv(utils.get_demo_file(df))\n",
    "    df = df.loc[df.period == '2006-01-01_2019-01-01'].set_index('reg')\n",
    "    smb_ref = df.loc[int(rgi_reg), 'dmdtda']\n",
    "\n",
    "    # Diff between the two\n",
    "    residual = smb_ref - smb_oggm\n",
    "\n",
    "    # Let's just shift\n",
    "    log.workflow('Shifting regional MB bias by {}'.format(residual))\n",
    "    log.workflow('Observations give {}'.format(smb_ref))\n",
    "    log.workflow('OGGM SMB gives {}'.format(out_smb))\n",
    "    log.workflow('OGGM frontal ablation gives {}'.format(out_cal))\n",
    "    for gdir in gdirs:\n",
    "        try:\n",
    "            df = gdir.read_json('local_mustar')\n",
    "            gdir.add_to_diagnostics('mb_bias_before_geodetic_corr', df['bias'])\n",
    "            df['bias'] = df['bias'] - residual\n",
    "            gdir.write_json(df, 'local_mustar')\n",
    "        except FileNotFoundError:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess a subset of an RGI region\n",
    "This example shows how to run the first steps of the OGGM preprocessing chain for a subset of the Alps - the Rofental catchment in the Austrian Alps (see [docs.oggm.org](http://docs.oggm.org/en/latest/run_examples/run_rgi_region.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import os\n",
    "\n",
    "# Libs\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as shpg\n",
    "\n",
    "# Locals\n",
    "from oggm import cfg, utils, workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OGGM and set up the default run parameters\n",
    "cfg.initialize()\n",
    "rgi_version = '62'\n",
    "rgi_region = '11'  # Alps\n",
    "\n",
    "# Local working directory (where OGGM will write its output)\n",
    "wdir = utils.gettempdir('match_regional_mb')\n",
    "utils.mkdir(wdir, reset=True)\n",
    "cfg.PATHS['working_dir'] = wdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use intersects\n",
    "path = utils.get_rgi_intersects_region_file(rgi_region, version=rgi_version)\n",
    "cfg.set_intersects_db(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RGI file\n",
    "path = utils.get_rgi_region_file(rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# Get the Rofental Basin file\n",
    "path = utils.get_demo_file('rofental_hydrosheds.shp')\n",
    "basin = gpd.read_file(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take all glaciers in the Rofental Basin\n",
    "in_bas = [basin.geometry.contains(shpg.Point(x, y))[0] for\n",
    "          (x, y) in zip(rgidf.CenLon, rgidf.CenLat)]\n",
    "rgidf = rgidf.loc[in_bas]\n",
    "# Store them for later\n",
    "rgidf.to_file(os.path.join(cfg.PATHS['working_dir'], 'rgi_rofental.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort for more efficient parallel computing\n",
    "rgidf = rgidf.sort_values('Area', ascending=False)\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "\n",
    "print('Starting OGGM run')\n",
    "print('Number of glaciers: {}'.format(len(rgidf)))\n",
    "\n",
    "# Go - initialize glacier directories\n",
    "gdirs_list = workflow.init_glacier_regions(rgidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select a number of glaciers\n",
    "gdirs = gdirs_list.copy()  # selecting all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from oggm.core import vascaling, climate\n",
    "# use default climate (=CRU), for HISTALP uncomment the following lines\n",
    "# cfg.PARAMS['baseline_climate'] = 'HISTALP'\n",
    "# cfg.PARAMS['prcp_scaling_factor'] = 1.75\n",
    "# cfg.PARAMS['temp_melt'] = -1.75\n",
    "\n",
    "# run all GIS tasks\n",
    "workflow.gis_prepro_tasks(gdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execute climate tasks\n",
    "workflow.execute_entity_task(climate.process_climate_data, gdirs);\n",
    "workflow.execute_entity_task(vascaling.local_t_star, gdirs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile output\n",
    "utils.compile_glacier_statistics(gdirs)\n",
    "utils.write_centerlines_to_shape(gdirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from os import path\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from oggm.utils import get_demo_file, gettempdir\n",
    "\n",
    "# Local working directory (where OGGM wrote its output)\n",
    "WORKING_DIR = cfg.PATHS['working_dir']\n",
    "\n",
    "# Plot: the basin, the outlines and the centerlines\n",
    "basin = gpd.read_file(get_demo_file('rofental_hydrosheds.shp'))\n",
    "rgi = gpd.read_file(path.join(WORKING_DIR, 'rgi_rofental.shp'))\n",
    "centerlines = gpd.read_file(path.join(WORKING_DIR, 'glacier_centerlines.shp'))\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "basin.plot(ax=ax, color='k', alpha=0.2)\n",
    "rgi.plot(ax=ax, color='C0')\n",
    "centerlines.plot(ax=ax, color='C3')\n",
    "plt.title('Rofental glaciers and centerlines')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Complete run for a list of glaciers\n",
    "This example shows how to run the OGGM model for a list of selected glaciers.\n",
    "\n",
    "Note that the default in OGGM is to use a previously calibrated list of $t^*$ for the run, which means that we don't have to calibrate the mass balance model ourselves (thankfully, otherwise you'd have to add all the calibration glaciers to your list too).\n",
    "\n",
    "Note that in order to be correct, the automated calibration can only be used if the model parameters don't change between the calibration and the run. After testing, it appears that changing the `border` parameter won't affect the results much (as expected). So it's ok to change this parameters. Some other parameters (e.g. topo smoothing, dx, precipitation factor, alternative climate data, ...) will probaly need a re-calibration step (see [3. Run the mass balance calibration](http://docs.oggm.org/en/latest/run_examples/run_mb_calibration.html)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(vascaling)\n",
    "importlib.reload(workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random climate representative for the tstar climate, without bias\n",
    "# In an ideal world this would imply that the glaciers remain stable,\n",
    "# but it doesn't have to be so\n",
    "nyears=200\n",
    "workflow.execute_entity_task(vascaling.run_random_climate, gdirs,\n",
    "                             nyears=nyears, bias=0, seed=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# create empty container\n",
    "volume_m3 = pd.DataFrame(index=np.arange(0,nyears))\n",
    "# iterate over all gdirs\n",
    "for gdir in gdirs:\n",
    "    path = gdir.get_filepath('model_diagnostics', filesuffix='vas')\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    vol = df.volume_m3\n",
    "    rgi_id = gdir.rgi_id\n",
    "    volume_m3[rgi_id] = vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_m3.sum(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test some stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as shpg\n",
    "\n",
    "# Locals\n",
    "import oggm.cfg as cfg\n",
    "from oggm import utils, workflow\n",
    "from oggm.core import vascaling, climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OGGM and set up the default run parameters\n",
    "cfg.initialize()\n",
    "rgi_version = '61'\n",
    "rgi_region = '11'  # Alps\n",
    "\n",
    "# Local working directory (where OGGM will write its output)\n",
    "\n",
    "wdir = '/Users/oberrauch/master/working_sirectories/commitment_run_vas/'\n",
    "utils.mkdir(wdir)\n",
    "cfg.PATHS['working_dir'] = wdir\n",
    "\n",
    "# We use intersects\n",
    "path = utils.get_rgi_intersects_region_file(rgi_region, version=rgi_version)\n",
    "cfg.set_intersects_db(path)\n",
    "\n",
    "# RGI file\n",
    "path = utils.get_rgi_region_file(rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# Get the Rofental Basin file\n",
    "path = utils.get_demo_file('rofental_hydrosheds.shp')\n",
    "basin = gpd.read_file(path)\n",
    "\n",
    "# Take all glaciers in the Rofental Basin\n",
    "in_bas = [basin.geometry.contains(shpg.Point(x, y))[0] for\n",
    "          (x, y) in zip(rgidf.CenLon, rgidf.CenLat)]\n",
    "rgidf = rgidf.loc[in_bas]\n",
    "# Store them for later\n",
    "rgidf.to_file(os.path.join(wdir, 'rgi_rofental.shp'))\n",
    "\n",
    "# Sort for more efficient parallel computing\n",
    "rgidf = rgidf.sort_values('Area', ascending=False)\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "\n",
    "# Go - initialize glacier directories\n",
    "gdirs = workflow.init_glacier_regions(rgidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Hintereisferener\n",
    "gdir = gdirs[0]\n",
    "cfg.PARAMS['baseline_climate'] = 'HISTALP'\n",
    "cfg.PARAMS['prcp_scaling_factor'] = 1.75\n",
    "cfg.PARAMS['temp_melt'] = -1.75\n",
    "vascaling.run_random_vas_climate(gdir, y0=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = gdir.get_filepath('model_diagnostics', filesuffix='vas')\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.volume_m3.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access `model_diagnostice` from already run gdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import shapely.geometry as shpg\n",
    "\n",
    "# Locals\n",
    "import oggm.cfg as cfg\n",
    "from oggm import utils, workflow\n",
    "from oggm.core import vascaling, climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OGGM and set up the default run parameters\n",
    "cfg.initialize()\n",
    "rgi_version = '61'\n",
    "rgi_region = '11'  # Alps\n",
    "\n",
    "# Local working directory (where OGGM will write its output)\n",
    "\n",
    "wdir = '/Users/oberrauch/master/working_sirectories/commitment_run_vas/'\n",
    "utils.mkdir(wdir)\n",
    "cfg.PATHS['working_dir'] = wdir\n",
    "\n",
    "# We use intersects\n",
    "path = utils.get_rgi_intersects_region_file(rgi_region, version=rgi_version)\n",
    "cfg.set_intersects_db(path)\n",
    "\n",
    "# RGI file\n",
    "path = utils.get_rgi_region_file(rgi_region, version=rgi_version)\n",
    "rgidf = gpd.read_file(path)\n",
    "\n",
    "# Get the Rofental Basin file\n",
    "path = utils.get_demo_file('rofental_hydrosheds.shp')\n",
    "basin = gpd.read_file(path)\n",
    "\n",
    "# Take all glaciers in the Rofental Basin\n",
    "in_bas = [basin.geometry.contains(shpg.Point(x, y))[0] for\n",
    "          (x, y) in zip(rgidf.CenLon, rgidf.CenLat)]\n",
    "rgidf = rgidf.loc[in_bas]\n",
    "# Store them for later\n",
    "rgidf.to_file(os.path.join(wdir, 'rgi_rofental.shp'))\n",
    "\n",
    "# Sort for more efficient parallel computing\n",
    "rgidf = rgidf.sort_values('Area', ascending=False)\n",
    "cfg.PARAMS['use_multiprocessing'] = True\n",
    "\n",
    "# Go - initialize glacier directories\n",
    "gdirs = workflow.init_glacier_regions(rgidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyears = 300\n",
    "# create empty container\n",
    "volume_m3 = pd.DataFrame(index=np.arange(0,nyears))\n",
    "# iterate over all gdirs\n",
    "for gdir in gdirs:\n",
    "    path = gdir.get_filepath('model_diagnostics', filesuffix='vas')\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    vol = df.volume_m3\n",
    "    rgi_id = gdir.rgi_id\n",
    "    volume_m3[rgi_id] = vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_m3.sum(axis=1).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from oggm.utils import get_demo_file, gettempdir\n",
    "\n",
    "# Local working directory (where OGGM wrote its output)\n",
    "wdir = '/Users/oberrauch/master/working_sirectories/commitment_run_oggm/'\n",
    "# Read the files using xarray\n",
    "ds = xr.open_dataset(os.path.join(wdir, 'run_output_commitment.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume\n",
    "(ds.volume.sum(dim='rgi_id')).plot(label='OGGM')\n",
    "volume_m3.sum(axis=1).plot(label='VAS')\n",
    "plt.legend()\n",
    "plt.title('Overall glacier volume - Rofental')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Volume [m$^3$]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local working directory (where OGGM will write its output)\n",
    "wdir = '/Users/oberrauch/master/working_sirectories/commitment_run_oggm/'\n",
    "utils.mkdir(wdir, reset=False)\n",
    "cfg.PATHS['working_dir'] = wdir\n",
    "gdirs = workflow.init_glacier_regions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from oggm.core import flowline\n",
    "flowline.init_present_time_glacier(gdirs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.PARAMS['baseline_climate'] = 'HISTALP'\n",
    "cfg.PARAMS['prcp_scaling_factor'] = 1.75\n",
    "cfg.PARAMS['temp_melt'] = -1.75\n",
    "flowline.run_random_climate(gdirs[1], nyears=300, y0=1999, seed=2,\n",
    "                            output_filesuffix='_commitment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = gdirs[1].get_filepath('model_diagnostics', filesuffix='_commitment')\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyears = 300\n",
    "# create empty container\n",
    "volume_m3 = pd.DataFrame(index=np.arange(0,nyears))\n",
    "# iterate over all gdirs\n",
    "for gdir in gdirs:\n",
    "\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    vol = df.volume_m3\n",
    "    rgi_id = gdir.rgi_id\n",
    "    volume_m3[rgi_id] = vol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xa\n",
    "ds = xa.open_dataset(path)\n",
    "ds.volume_m3.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick test of RandomClimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick-test of the RandomVASMassBalanceModel\n",
    "import importlib\n",
    "importlib.reload(vascaling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select Hintereisferner gdir\n",
    "gdir = gdirs[int(np.where([gdir.name == 'Hintereisferner' for gdir in gdirs])[0])]\n",
    "gdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_mbmod = vascaling.RandomVASMassBalance(gdir=gdir, seed=12, y0=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_hgt, max_hgt = vascaling.get_min_max_elevation(gdir)\n",
    "year = 2043\n",
    "r_yr = rand_mbmod.get_state_yr(year)\n",
    "mb = rand_mbmod.get_specific_mb(min_hgt, max_hgt, year)\n",
    "print('Year {} correpsonds to mb year {}, resulting in {} mm w.e. yr-1'.format(year, r_yr, mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2018, 2200)\n",
    "mb = np.empty(years.size)\n",
    "r_yrs = np.empty(years.size)\n",
    "for i, year in enumerate(years):\n",
    "    mb[i] = rand_mbmod.get_specific_mb(min_hgt, max_hgt, year)\n",
    "    r_yrs[i] = rand_mbmod.get_state_yr(year)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'mb':mb, 'r_yr':r_yrs}, index=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mb.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_tstar = gdir.read_json('vascaling_mustar')\n",
    "t_star = local_tstar['t_star']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "df.r_yr.plot()\n",
    "plt.axhline(t_star-15)\n",
    "plt.axhline(t_star+15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls /Users/oberrauch/master/working_sirectories/commitment_run_vas/per_glacier/RGI60-11/RGI60-11.00/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store to xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/oberrauch/master/working_sirectories/commitment_run_oggm/'+\\\n",
    "    'per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00731/model_run_commitment.nc'\n",
    "import xarray as xr\n",
    "xr.open_dataarray(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/oberrauch/master/working_sirectories/commitment_run_vas/'+\\\n",
    "    'per_glacier/RGI60-11/RGI60-11.00/RGI60-11.00739/model_diagnosticsvas.nc'\n",
    "df = pd.read_csv(path, index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_ds = xr.Dataset()\n",
    "\n",
    "# Global attributes\n",
    "diag_ds.attrs['description'] = 'OGGM model output'\n",
    "# diag_ds.attrs['oggm_version'] = __version__\n",
    "diag_ds.attrs['calendar'] = '365-day no leap'\n",
    "diag_ds.attrs['creation_date'] = strftime(\"%Y-%m-%d %H:%M:%S\",\n",
    "                                          gmtime())\n",
    "\n",
    "\n",
    "diag_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coordinates\n",
    "diag_ds.coords['time'] = ('time', monthly_time)\n",
    "diag_ds.coords['hydro_year'] = ('time', yrs)\n",
    "diag_ds.coords['hydro_month'] = ('time', months)\n",
    "diag_ds.coords['calendar_year'] = ('time', cyrs)\n",
    "diag_ds.coords['calendar_month'] = ('time', cmonths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.monthly_timeseries(20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time\n",
    "        yearly_time = np.arange(np.floor(self.yr), np.floor(y1)+1)\n",
    "\n",
    "        if store_monthly_step:\n",
    "            monthly_time = utils.monthly_timeseries(self.yr, y1)\n",
    "        else:\n",
    "            monthly_time = np.arange(np.floor(self.yr), np.floor(y1)+1)\n",
    "        yrs, months = utils.floatyear_to_date(monthly_time)\n",
    "        cyrs, cmonths = utils.hydrodate_to_calendardate(yrs, months)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
